# Glossary of Terms

## Adversarial Collaboration
A method of working with AI where both human and AI agents engage in a dialogic exchange, often involving counter-arguments or alternative suggestions, to enhance critical thinking and maintain a dynamic interaction.

## Epistemic Agency
The ability of a developer to act as a knowledgeable agent with autonomy over decisions, ensuring active participation in the decision-making process when collaborating with AI tools.

## Zero Trust Framework
An approach where AI outputs are not automatically trusted and are subject to scrutiny, validation, and challenge to ensure correctness and reliability.

## Transparency and Explainability
The practice of ensuring AI tools provide not just suggestions, but also the underlying reasoning and context behind those suggestions, allowing for informed decision-making.

## Dynamic Feedback Loops
A workflow design that creates a constant feedback loop between AI and human agents, where each AI output is immediately followed by a counter-argument, modification, or validation check.

## Auto-Testing
A process of continuous testing with every change to validate all AI-generated code, ensuring robustness and security.

## Selective Committing
The practice of manually reviewing and committing changes after verifying their correctness, maintaining human control over the codebase integrity.
